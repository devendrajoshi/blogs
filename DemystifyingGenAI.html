<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=dpiI8CyVsrzWsJLBFKehGpLhv3qFjX7dUn1mYxfCXhI);ul.lst-kix_s6uqenm43v18-8{list-style-type:none}.lst-kix_ovz8ddkz44wu-0>li{counter-increment:lst-ctn-kix_ovz8ddkz44wu-0}.lst-kix_j5ci3q21dttk-2>li:before{content:"\0025a0   "}.lst-kix_j5ci3q21dttk-3>li:before{content:"\0025cf   "}.lst-kix_j5ci3q21dttk-0>li:before{content:"\0025cf   "}.lst-kix_j5ci3q21dttk-1>li:before{content:"\0025cb   "}.lst-kix_j5ci3q21dttk-4>li:before{content:"\0025cb   "}.lst-kix_j5ci3q21dttk-5>li:before{content:"\0025a0   "}ul.lst-kix_ok66euexs0s0-8{list-style-type:none}ul.lst-kix_j5ci3q21dttk-2{list-style-type:none}ul.lst-kix_ok66euexs0s0-6{list-style-type:none}.lst-kix_5sv5ylbljkvg-6>li{counter-increment:lst-ctn-kix_5sv5ylbljkvg-6}ul.lst-kix_j5ci3q21dttk-3{list-style-type:none}ul.lst-kix_ok66euexs0s0-7{list-style-type:none}ol.lst-kix_5sv5ylbljkvg-0.start{counter-reset:lst-ctn-kix_5sv5ylbljkvg-0 0}ul.lst-kix_j5ci3q21dttk-0{list-style-type:none}ul.lst-kix_ok66euexs0s0-4{list-style-type:none}ul.lst-kix_j5ci3q21dttk-1{list-style-type:none}ul.lst-kix_ok66euexs0s0-5{list-style-type:none}ul.lst-kix_ok66euexs0s0-2{list-style-type:none}.lst-kix_j5ci3q21dttk-8>li:before{content:"\0025a0   "}ul.lst-kix_ok66euexs0s0-3{list-style-type:none}ul.lst-kix_ok66euexs0s0-0{list-style-type:none}ul.lst-kix_ok66euexs0s0-1{list-style-type:none}.lst-kix_j5ci3q21dttk-6>li:before{content:"\0025cf   "}.lst-kix_j5ci3q21dttk-7>li:before{content:"\0025cb   "}ul.lst-kix_j5ci3q21dttk-8{list-style-type:none}ul.lst-kix_j5ci3q21dttk-6{list-style-type:none}ul.lst-kix_j5ci3q21dttk-7{list-style-type:none}ul.lst-kix_j5ci3q21dttk-4{list-style-type:none}ul.lst-kix_j5ci3q21dttk-5{list-style-type:none}.lst-kix_kkmtp1dl1dg0-4>li:before{content:"\0025cb   "}.lst-kix_kkmtp1dl1dg0-5>li:before{content:"\0025a0   "}.lst-kix_kkmtp1dl1dg0-6>li:before{content:"\0025cf   "}.lst-kix_kkmtp1dl1dg0-7>li:before{content:"\0025cb   "}ol.lst-kix_5sv5ylbljkvg-6.start{counter-reset:lst-ctn-kix_5sv5ylbljkvg-6 0}.lst-kix_kkmtp1dl1dg0-8>li:before{content:"\0025a0   "}ol.lst-kix_ovz8ddkz44wu-1.start{counter-reset:lst-ctn-kix_ovz8ddkz44wu-1 0}ul.lst-kix_bkfzrqrpqj20-8{list-style-type:none}ul.lst-kix_bkfzrqrpqj20-2{list-style-type:none}ul.lst-kix_bkfzrqrpqj20-3{list-style-type:none}ul.lst-kix_bkfzrqrpqj20-0{list-style-type:none}ul.lst-kix_bkfzrqrpqj20-1{list-style-type:none}ul.lst-kix_bkfzrqrpqj20-6{list-style-type:none}ul.lst-kix_bkfzrqrpqj20-7{list-style-type:none}ul.lst-kix_bkfzrqrpqj20-4{list-style-type:none}ul.lst-kix_bkfzrqrpqj20-5{list-style-type:none}.lst-kix_ovz8ddkz44wu-2>li{counter-increment:lst-ctn-kix_ovz8ddkz44wu-2}.lst-kix_kkmtp1dl1dg0-3>li:before{content:"\0025cf   "}.lst-kix_5sv5ylbljkvg-4>li:before{content:"" counter(lst-ctn-kix_5sv5ylbljkvg-4,lower-latin) ". "}.lst-kix_5sv5ylbljkvg-4>li{counter-increment:lst-ctn-kix_5sv5ylbljkvg-4}.lst-kix_950oqqc6e3hw-5>li:before{content:"\0025a0   "}.lst-kix_5sv5ylbljkvg-5>li:before{content:"" counter(lst-ctn-kix_5sv5ylbljkvg-5,lower-roman) ". "}.lst-kix_950oqqc6e3hw-6>li:before{content:"\0025cf   "}.lst-kix_kkmtp1dl1dg0-2>li:before{content:"\0025a0   "}.lst-kix_5sv5ylbljkvg-6>li:before{content:"" counter(lst-ctn-kix_5sv5ylbljkvg-6,decimal) ". "}.lst-kix_950oqqc6e3hw-7>li:before{content:"\0025cb   "}.lst-kix_kkmtp1dl1dg0-1>li:before{content:"\0025cb   "}.lst-kix_5sv5ylbljkvg-7>li:before{content:"" counter(lst-ctn-kix_5sv5ylbljkvg-7,lower-latin) ". "}.lst-kix_950oqqc6e3hw-8>li:before{content:"\0025a0   "}.lst-kix_kkmtp1dl1dg0-0>li:before{content:"\0025cf   "}ul.lst-kix_pe7i3notdr30-2{list-style-type:none}ul.lst-kix_pe7i3notdr30-1{list-style-type:none}ul.lst-kix_pe7i3notdr30-0{list-style-type:none}ul.lst-kix_pe7i3notdr30-6{list-style-type:none}ul.lst-kix_pe7i3notdr30-5{list-style-type:none}ul.lst-kix_pe7i3notdr30-4{list-style-type:none}ul.lst-kix_pe7i3notdr30-3{list-style-type:none}ul.lst-kix_pe7i3notdr30-8{list-style-type:none}ul.lst-kix_pe7i3notdr30-7{list-style-type:none}.lst-kix_5sv5ylbljkvg-3>li:before{content:"" counter(lst-ctn-kix_5sv5ylbljkvg-3,decimal) ". "}.lst-kix_950oqqc6e3hw-4>li:before{content:"\0025cb   "}.lst-kix_5sv5ylbljkvg-2>li:before{content:"\0025a0   "}.lst-kix_950oqqc6e3hw-3>li:before{content:"\0025cf   "}.lst-kix_rv0f7hiv8gcy-0>li:before{content:"\0025cf   "}.lst-kix_5sv5ylbljkvg-0>li:before{content:"" counter(lst-ctn-kix_5sv5ylbljkvg-0,decimal) ". "}ul.lst-kix_o92df0wacpmc-6{list-style-type:none}.lst-kix_950oqqc6e3hw-1>li:before{content:"\0025cb   "}ul.lst-kix_o92df0wacpmc-7{list-style-type:none}.lst-kix_5sv5ylbljkvg-1>li:before{content:"\0025cb   "}ul.lst-kix_o92df0wacpmc-8{list-style-type:none}.lst-kix_950oqqc6e3hw-2>li:before{content:"\0025a0   "}ul.lst-kix_o92df0wacpmc-2{list-style-type:none}ul.lst-kix_o92df0wacpmc-3{list-style-type:none}ul.lst-kix_o92df0wacpmc-4{list-style-type:none}ul.lst-kix_o92df0wacpmc-5{list-style-type:none}ul.lst-kix_o92df0wacpmc-0{list-style-type:none}.lst-kix_950oqqc6e3hw-0>li:before{content:"\0025cf   "}ul.lst-kix_o92df0wacpmc-1{list-style-type:none}.lst-kix_ducrbna9xmea-6>li:before{content:"\0025cf   "}.lst-kix_ovz8ddkz44wu-0>li:before{content:"" counter(lst-ctn-kix_ovz8ddkz44wu-0,decimal) ". "}.lst-kix_ovz8ddkz44wu-2>li:before{content:"" counter(lst-ctn-kix_ovz8ddkz44wu-2,lower-roman) ". "}.lst-kix_rv0f7hiv8gcy-7>li:before{content:"\0025cb   "}.lst-kix_ovz8ddkz44wu-4>li:before{content:"" counter(lst-ctn-kix_ovz8ddkz44wu-4,lower-latin) ". "}.lst-kix_ducrbna9xmea-4>li:before{content:"\0025cb   "}.lst-kix_d9oma2969bjs-8>li:before{content:"\0025a0   "}.lst-kix_rv0f7hiv8gcy-1>li:before{content:"\0025cb   "}ul.lst-kix_rv0f7hiv8gcy-4{list-style-type:none}ul.lst-kix_rv0f7hiv8gcy-5{list-style-type:none}ul.lst-kix_rv0f7hiv8gcy-6{list-style-type:none}.lst-kix_ovz8ddkz44wu-8>li:before{content:"" counter(lst-ctn-kix_ovz8ddkz44wu-8,lower-roman) ". "}ul.lst-kix_rv0f7hiv8gcy-7{list-style-type:none}ul.lst-kix_rv0f7hiv8gcy-8{list-style-type:none}.lst-kix_s6uqenm43v18-7>li:before{content:"\0025cb   "}.lst-kix_rv0f7hiv8gcy-3>li:before{content:"\0025cf   "}.lst-kix_ovz8ddkz44wu-6>li:before{content:"" counter(lst-ctn-kix_ovz8ddkz44wu-6,decimal) ". "}.lst-kix_ducrbna9xmea-8>li:before{content:"\0025a0   "}.lst-kix_rv0f7hiv8gcy-5>li:before{content:"\0025a0   "}ol.lst-kix_ovz8ddkz44wu-7.start{counter-reset:lst-ctn-kix_ovz8ddkz44wu-7 0}.lst-kix_5sv5ylbljkvg-0>li{counter-increment:lst-ctn-kix_5sv5ylbljkvg-0}ol.lst-kix_ovz8ddkz44wu-4.start{counter-reset:lst-ctn-kix_ovz8ddkz44wu-4 0}.lst-kix_ovz8ddkz44wu-4>li{counter-increment:lst-ctn-kix_ovz8ddkz44wu-4}ol.lst-kix_5sv5ylbljkvg-0{list-style-type:none}.lst-kix_ok66euexs0s0-2>li:before{content:"\0025a0   "}.lst-kix_ok66euexs0s0-4>li:before{content:"\0025cb   "}.lst-kix_j78f6nqeir9j-7>li:before{content:"\0025cb   "}.lst-kix_12qdo184rrs4-6>li:before{content:"\0025cf   "}ol.lst-kix_5sv5ylbljkvg-7{list-style-type:none}ol.lst-kix_5sv5ylbljkvg-8{list-style-type:none}.lst-kix_ok66euexs0s0-0>li:before{content:"\0025cf   "}.lst-kix_ok66euexs0s0-8>li:before{content:"\0025a0   "}ol.lst-kix_5sv5ylbljkvg-5{list-style-type:none}.lst-kix_12qdo184rrs4-8>li:before{content:"\0025a0   "}.lst-kix_ovz8ddkz44wu-3>li{counter-increment:lst-ctn-kix_ovz8ddkz44wu-3}ol.lst-kix_5sv5ylbljkvg-6{list-style-type:none}ol.lst-kix_5sv5ylbljkvg-3{list-style-type:none}ol.lst-kix_5sv5ylbljkvg-4{list-style-type:none}.lst-kix_j78f6nqeir9j-3>li:before{content:"\0025cf   "}.lst-kix_ok66euexs0s0-6>li:before{content:"\0025cf   "}.lst-kix_j78f6nqeir9j-5>li:before{content:"\0025a0   "}ol.lst-kix_ovz8ddkz44wu-5.start{counter-reset:lst-ctn-kix_ovz8ddkz44wu-5 0}ul.lst-kix_tz6i84wciuj5-0{list-style-type:none}ul.lst-kix_tz6i84wciuj5-2{list-style-type:none}.lst-kix_bkfzrqrpqj20-7>li:before{content:"\0025cb   "}ul.lst-kix_tz6i84wciuj5-1{list-style-type:none}ul.lst-kix_tz6i84wciuj5-4{list-style-type:none}ul.lst-kix_tz6i84wciuj5-3{list-style-type:none}ul.lst-kix_tz6i84wciuj5-6{list-style-type:none}ul.lst-kix_tz6i84wciuj5-5{list-style-type:none}.lst-kix_12qdo184rrs4-0>li:before{content:"\0025cf   "}ul.lst-kix_tz6i84wciuj5-8{list-style-type:none}.lst-kix_d9oma2969bjs-0>li:before{content:"\0025cf   "}.lst-kix_j78f6nqeir9j-1>li:before{content:"\0025cb   "}ul.lst-kix_tz6i84wciuj5-7{list-style-type:none}ul.lst-kix_s6uqenm43v18-3{list-style-type:none}ul.lst-kix_s6uqenm43v18-2{list-style-type:none}.lst-kix_12qdo184rrs4-2>li:before{content:"\0025a0   "}ul.lst-kix_s6uqenm43v18-1{list-style-type:none}ul.lst-kix_s6uqenm43v18-0{list-style-type:none}ul.lst-kix_s6uqenm43v18-7{list-style-type:none}ul.lst-kix_s6uqenm43v18-6{list-style-type:none}ul.lst-kix_s6uqenm43v18-5{list-style-type:none}.lst-kix_d9oma2969bjs-2>li:before{content:"\0025a0   "}.lst-kix_d9oma2969bjs-6>li:before{content:"\0025cf   "}ul.lst-kix_s6uqenm43v18-4{list-style-type:none}ol.lst-kix_ovz8ddkz44wu-6.start{counter-reset:lst-ctn-kix_ovz8ddkz44wu-6 0}.lst-kix_5sv5ylbljkvg-5>li{counter-increment:lst-ctn-kix_5sv5ylbljkvg-5}.lst-kix_12qdo184rrs4-4>li:before{content:"\0025cb   "}.lst-kix_d9oma2969bjs-4>li:before{content:"\0025cb   "}.lst-kix_o92df0wacpmc-4>li:before{content:"\0025cb   "}.lst-kix_o92df0wacpmc-6>li:before{content:"\0025cf   "}.lst-kix_o92df0wacpmc-3>li:before{content:"\0025cf   "}.lst-kix_o92df0wacpmc-7>li:before{content:"\0025cb   "}.lst-kix_bkfzrqrpqj20-0>li:before{content:"\0025cf   "}.lst-kix_bkfzrqrpqj20-1>li:before{content:"\0025cb   "}ol.lst-kix_5sv5ylbljkvg-8.start{counter-reset:lst-ctn-kix_5sv5ylbljkvg-8 0}ol.lst-kix_ovz8ddkz44wu-3.start{counter-reset:lst-ctn-kix_ovz8ddkz44wu-3 0}.lst-kix_o92df0wacpmc-5>li:before{content:"\0025a0   "}.lst-kix_bkfzrqrpqj20-3>li:before{content:"\0025cf   "}.lst-kix_bkfzrqrpqj20-2>li:before{content:"\0025a0   "}.lst-kix_bkfzrqrpqj20-4>li:before{content:"\0025cb   "}.lst-kix_bkfzrqrpqj20-6>li:before{content:"\0025cf   "}.lst-kix_o92df0wacpmc-8>li:before{content:"\0025a0   "}.lst-kix_bkfzrqrpqj20-5>li:before{content:"\0025a0   "}.lst-kix_5sv5ylbljkvg-7>li{counter-increment:lst-ctn-kix_5sv5ylbljkvg-7}.lst-kix_xuct0t6o06gb-3>li:before{content:"\0025cf   "}ol.lst-kix_5sv5ylbljkvg-3.start{counter-reset:lst-ctn-kix_5sv5ylbljkvg-3 0}.lst-kix_xuct0t6o06gb-2>li:before{content:"\0025a0   "}.lst-kix_xuct0t6o06gb-1>li:before{content:"\0025cb   "}.lst-kix_ovz8ddkz44wu-1>li{counter-increment:lst-ctn-kix_ovz8ddkz44wu-1}.lst-kix_o92df0wacpmc-0>li:before{content:"\0025cf   "}.lst-kix_o92df0wacpmc-2>li:before{content:"\0025a0   "}.lst-kix_xuct0t6o06gb-0>li:before{content:"\0025cf   "}.lst-kix_o92df0wacpmc-1>li:before{content:"\0025cb   "}ul.lst-kix_d9oma2969bjs-4{list-style-type:none}.lst-kix_pe7i3notdr30-1>li:before{content:"\0027a2   "}.lst-kix_tz6i84wciuj5-2>li:before{content:"\0025a0   "}ul.lst-kix_d9oma2969bjs-5{list-style-type:none}ul.lst-kix_d9oma2969bjs-2{list-style-type:none}.lst-kix_pe7i3notdr30-0>li:before{content:"\002756   "}.lst-kix_pe7i3notdr30-2>li:before{content:"\0025a0   "}ul.lst-kix_d9oma2969bjs-3{list-style-type:none}ul.lst-kix_d9oma2969bjs-0{list-style-type:none}ul.lst-kix_d9oma2969bjs-1{list-style-type:none}.lst-kix_tz6i84wciuj5-3>li:before{content:"\0025cf   "}.lst-kix_pe7i3notdr30-5>li:before{content:"\0027a2   "}ul.lst-kix_950oqqc6e3hw-7{list-style-type:none}ul.lst-kix_950oqqc6e3hw-6{list-style-type:none}.lst-kix_pe7i3notdr30-4>li:before{content:"\0025c6   "}ul.lst-kix_950oqqc6e3hw-8{list-style-type:none}ul.lst-kix_d9oma2969bjs-8{list-style-type:none}ol.lst-kix_ovz8ddkz44wu-8.start{counter-reset:lst-ctn-kix_ovz8ddkz44wu-8 0}.lst-kix_pe7i3notdr30-3>li:before{content:"\0025cf   "}.lst-kix_tz6i84wciuj5-0>li:before{content:"\0025cf   "}.lst-kix_tz6i84wciuj5-8>li:before{content:"\0025a0   "}ul.lst-kix_d9oma2969bjs-6{list-style-type:none}.lst-kix_ovz8ddkz44wu-8>li{counter-increment:lst-ctn-kix_ovz8ddkz44wu-8}.lst-kix_tz6i84wciuj5-1>li:before{content:"\0025cb   "}ul.lst-kix_d9oma2969bjs-7{list-style-type:none}.lst-kix_pe7i3notdr30-8>li:before{content:"\0025c6   "}ul.lst-kix_950oqqc6e3hw-1{list-style-type:none}.lst-kix_xuct0t6o06gb-4>li:before{content:"\0025cb   "}ul.lst-kix_950oqqc6e3hw-0{list-style-type:none}ul.lst-kix_950oqqc6e3hw-3{list-style-type:none}ul.lst-kix_950oqqc6e3hw-2{list-style-type:none}.lst-kix_tz6i84wciuj5-7>li:before{content:"\0025cb   "}ul.lst-kix_950oqqc6e3hw-5{list-style-type:none}.lst-kix_xuct0t6o06gb-5>li:before{content:"\0025a0   "}ul.lst-kix_950oqqc6e3hw-4{list-style-type:none}.lst-kix_tz6i84wciuj5-6>li:before{content:"\0025cf   "}.lst-kix_pe7i3notdr30-6>li:before{content:"\0025a0   "}.lst-kix_xuct0t6o06gb-6>li:before{content:"\0025cf   "}.lst-kix_xuct0t6o06gb-8>li:before{content:"\0025a0   "}.lst-kix_pe7i3notdr30-7>li:before{content:"\0025cf   "}.lst-kix_tz6i84wciuj5-4>li:before{content:"\0025cb   "}.lst-kix_tz6i84wciuj5-5>li:before{content:"\0025a0   "}.lst-kix_xuct0t6o06gb-7>li:before{content:"\0025cb   "}ul.lst-kix_ducrbna9xmea-8{list-style-type:none}ul.lst-kix_ducrbna9xmea-6{list-style-type:none}ul.lst-kix_ducrbna9xmea-7{list-style-type:none}ul.lst-kix_ducrbna9xmea-4{list-style-type:none}ol.lst-kix_5sv5ylbljkvg-7.start{counter-reset:lst-ctn-kix_5sv5ylbljkvg-7 0}ol.lst-kix_ovz8ddkz44wu-2.start{counter-reset:lst-ctn-kix_ovz8ddkz44wu-2 0}ul.lst-kix_ducrbna9xmea-5{list-style-type:none}ul.lst-kix_ducrbna9xmea-2{list-style-type:none}ul.lst-kix_kkmtp1dl1dg0-8{list-style-type:none}ul.lst-kix_ducrbna9xmea-3{list-style-type:none}ul.lst-kix_kkmtp1dl1dg0-7{list-style-type:none}ul.lst-kix_ducrbna9xmea-0{list-style-type:none}ul.lst-kix_kkmtp1dl1dg0-6{list-style-type:none}ul.lst-kix_ducrbna9xmea-1{list-style-type:none}ul.lst-kix_kkmtp1dl1dg0-5{list-style-type:none}ul.lst-kix_rv0f7hiv8gcy-0{list-style-type:none}ul.lst-kix_rv0f7hiv8gcy-1{list-style-type:none}ul.lst-kix_rv0f7hiv8gcy-2{list-style-type:none}ul.lst-kix_rv0f7hiv8gcy-3{list-style-type:none}ul.lst-kix_kkmtp1dl1dg0-0{list-style-type:none}.lst-kix_s6uqenm43v18-4>li:before{content:"\0025cb   "}.lst-kix_s6uqenm43v18-5>li:before{content:"\0025a0   "}.lst-kix_ducrbna9xmea-0>li:before{content:"\0025cf   "}ul.lst-kix_kkmtp1dl1dg0-4{list-style-type:none}.lst-kix_s6uqenm43v18-3>li:before{content:"\0025cf   "}ul.lst-kix_kkmtp1dl1dg0-3{list-style-type:none}ul.lst-kix_kkmtp1dl1dg0-2{list-style-type:none}ul.lst-kix_kkmtp1dl1dg0-1{list-style-type:none}.lst-kix_ducrbna9xmea-2>li:before{content:"\0025a0   "}.lst-kix_s6uqenm43v18-0>li:before{content:"\0025cf   "}.lst-kix_s6uqenm43v18-1>li:before{content:"\0025cb   "}.lst-kix_ducrbna9xmea-1>li:before{content:"\0025cb   "}.lst-kix_s6uqenm43v18-2>li:before{content:"\0025a0   "}.lst-kix_ovz8ddkz44wu-1>li:before{content:"" counter(lst-ctn-kix_ovz8ddkz44wu-1,lower-latin) ". "}.lst-kix_ducrbna9xmea-7>li:before{content:"\0025cb   "}.lst-kix_rv0f7hiv8gcy-6>li:before{content:"\0025cf   "}.lst-kix_rv0f7hiv8gcy-8>li:before{content:"\0025a0   "}.lst-kix_ovz8ddkz44wu-6>li{counter-increment:lst-ctn-kix_ovz8ddkz44wu-6}.lst-kix_ovz8ddkz44wu-5>li:before{content:"" counter(lst-ctn-kix_ovz8ddkz44wu-5,lower-roman) ". "}.lst-kix_ducrbna9xmea-3>li:before{content:"\0025cf   "}.lst-kix_d9oma2969bjs-7>li:before{content:"\0025cb   "}.lst-kix_rv0f7hiv8gcy-2>li:before{content:"\0025a0   "}.lst-kix_ovz8ddkz44wu-3>li:before{content:"" counter(lst-ctn-kix_ovz8ddkz44wu-3,decimal) ". "}.lst-kix_ducrbna9xmea-5>li:before{content:"\0025a0   "}.lst-kix_s6uqenm43v18-6>li:before{content:"\0025cf   "}ol.lst-kix_5sv5ylbljkvg-4.start{counter-reset:lst-ctn-kix_5sv5ylbljkvg-4 0}.lst-kix_ovz8ddkz44wu-5>li{counter-increment:lst-ctn-kix_ovz8ddkz44wu-5}.lst-kix_s6uqenm43v18-8>li:before{content:"\0025a0   "}.lst-kix_rv0f7hiv8gcy-4>li:before{content:"\0025cb   "}.lst-kix_ovz8ddkz44wu-7>li:before{content:"" counter(lst-ctn-kix_ovz8ddkz44wu-7,lower-latin) ". "}.lst-kix_5sv5ylbljkvg-3>li{counter-increment:lst-ctn-kix_5sv5ylbljkvg-3}.lst-kix_5sv5ylbljkvg-8>li:before{content:"" counter(lst-ctn-kix_5sv5ylbljkvg-8,lower-roman) ". "}.lst-kix_ovz8ddkz44wu-7>li{counter-increment:lst-ctn-kix_ovz8ddkz44wu-7}ul.lst-kix_j78f6nqeir9j-6{list-style-type:none}ul.lst-kix_j78f6nqeir9j-7{list-style-type:none}ul.lst-kix_j78f6nqeir9j-4{list-style-type:none}ul.lst-kix_j78f6nqeir9j-5{list-style-type:none}ul.lst-kix_j78f6nqeir9j-2{list-style-type:none}ul.lst-kix_j78f6nqeir9j-3{list-style-type:none}ul.lst-kix_j78f6nqeir9j-0{list-style-type:none}ul.lst-kix_j78f6nqeir9j-1{list-style-type:none}.lst-kix_ok66euexs0s0-3>li:before{content:"\0025cf   "}.lst-kix_ok66euexs0s0-7>li:before{content:"\0025cb   "}.lst-kix_j78f6nqeir9j-8>li:before{content:"\0025a0   "}ul.lst-kix_j78f6nqeir9j-8{list-style-type:none}.lst-kix_12qdo184rrs4-7>li:before{content:"\0025cb   "}.lst-kix_ok66euexs0s0-1>li:before{content:"\0025cb   "}ul.lst-kix_12qdo184rrs4-4{list-style-type:none}ul.lst-kix_12qdo184rrs4-5{list-style-type:none}.lst-kix_j78f6nqeir9j-4>li:before{content:"\0025cb   "}ul.lst-kix_12qdo184rrs4-2{list-style-type:none}.lst-kix_j78f6nqeir9j-2>li:before{content:"\0025a0   "}ul.lst-kix_12qdo184rrs4-3{list-style-type:none}ul.lst-kix_12qdo184rrs4-0{list-style-type:none}ul.lst-kix_12qdo184rrs4-1{list-style-type:none}.lst-kix_j78f6nqeir9j-6>li:before{content:"\0025cf   "}ul.lst-kix_12qdo184rrs4-8{list-style-type:none}ul.lst-kix_12qdo184rrs4-6{list-style-type:none}.lst-kix_ok66euexs0s0-5>li:before{content:"\0025a0   "}ul.lst-kix_12qdo184rrs4-7{list-style-type:none}ol.lst-kix_ovz8ddkz44wu-5{list-style-type:none}ol.lst-kix_ovz8ddkz44wu-6{list-style-type:none}ol.lst-kix_ovz8ddkz44wu-7{list-style-type:none}ol.lst-kix_ovz8ddkz44wu-8{list-style-type:none}ul.lst-kix_5sv5ylbljkvg-1{list-style-type:none}ol.lst-kix_5sv5ylbljkvg-5.start{counter-reset:lst-ctn-kix_5sv5ylbljkvg-5 0}ol.lst-kix_ovz8ddkz44wu-0.start{counter-reset:lst-ctn-kix_ovz8ddkz44wu-0 0}ul.lst-kix_5sv5ylbljkvg-2{list-style-type:none}ul.lst-kix_xuct0t6o06gb-6{list-style-type:none}ul.lst-kix_xuct0t6o06gb-5{list-style-type:none}ul.lst-kix_xuct0t6o06gb-8{list-style-type:none}.lst-kix_bkfzrqrpqj20-8>li:before{content:"\0025a0   "}.lst-kix_d9oma2969bjs-1>li:before{content:"\0025cb   "}.lst-kix_j78f6nqeir9j-0>li:before{content:"\0025cf   "}ul.lst-kix_xuct0t6o06gb-7{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ul.lst-kix_xuct0t6o06gb-0{list-style-type:none}.lst-kix_d9oma2969bjs-3>li:before{content:"\0025cf   "}.lst-kix_d9oma2969bjs-5>li:before{content:"\0025a0   "}ul.lst-kix_xuct0t6o06gb-2{list-style-type:none}.lst-kix_5sv5ylbljkvg-8>li{counter-increment:lst-ctn-kix_5sv5ylbljkvg-8}ul.lst-kix_xuct0t6o06gb-1{list-style-type:none}.lst-kix_12qdo184rrs4-1>li:before{content:"\0025cb   "}ul.lst-kix_xuct0t6o06gb-4{list-style-type:none}.lst-kix_12qdo184rrs4-5>li:before{content:"\0025a0   "}ul.lst-kix_xuct0t6o06gb-3{list-style-type:none}ol.lst-kix_ovz8ddkz44wu-0{list-style-type:none}ol.lst-kix_ovz8ddkz44wu-1{list-style-type:none}ol.lst-kix_ovz8ddkz44wu-2{list-style-type:none}ol.lst-kix_ovz8ddkz44wu-3{list-style-type:none}.lst-kix_12qdo184rrs4-3>li:before{content:"\0025cf   "}ol.lst-kix_ovz8ddkz44wu-4{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c18{border-right-style:solid;border-top-width:0pt;border-right-width:0pt;padding-left:0pt;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;padding-right:0pt}.c22{background-color:#ffffff;margin-left:36pt;padding-top:9pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c7{-webkit-text-decoration-skip:none;color:#1155cc;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:11pt;font-family:"Arial";font-style:normal}.c4{margin-left:36pt;padding-top:12pt;padding-left:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c9{margin-left:141pt;padding-top:12pt;padding-left:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c11{padding-top:12pt;padding-bottom:12pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c14{color:#111111;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Roboto";font-style:normal}.c20{padding-top:0pt;padding-bottom:3pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:center}.c25{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Arial";font-style:normal}.c2{padding-top:0pt;padding-bottom:16pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c12{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c6{padding-top:14pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c21{color:#000000;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c17{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c13{color:#666666;text-decoration:none;vertical-align:baseline;font-size:15pt;font-family:"Arial";font-style:normal}.c3{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c15{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c27{font-size:12pt;font-family:"Roboto";color:#111111}.c28{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c10{padding:0;margin:0}.c19{margin-left:47pt;padding-left:0pt}.c30{background-color:#ffffff;color:#111111}.c16{margin-left:94pt;padding-left:0pt}.c8{color:inherit;text-decoration:inherit}.c29{font-weight:400}.c1{font-weight:700}.c23{margin-left:36pt}.c5{height:11pt}.c24{vertical-align:super}.c26{page-break-after:avoid}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c28 doc-content"><p class="c20 title" id="h.vukj7e13aey2"><span class="c25">Demystifying GenAI: A Developer&#39;s Perspective</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c3"><span class="c0">A couple of decades ago, the advent of big data technology sparked a frenzy of excitement and innovation. Organizations across industries rushed to harness its potential, often without fully understanding its appropriate applications. It took time for the community to realize that not every problem required a big data solution. Today, we are witnessing a similar trend with artificial intelligence (AI), particularly with the rise of Generative AI (GenAI). GenAI has quickly become synonymous with AI, capturing the imagination of businesses and developers alike. However, just as with big data, it&#39;s crucial to discern when and how to effectively leverage this powerful technology.</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c3"><span class="c0">While Generative AI (GenAI) has garnered significant attention, it&#39;s important to recognize that it represents just one facet of the broader AI landscape. AI encompasses a vast array of subfields and technologies, including machine learning, natural language processing, computer vision, robotics, and more. Each of these areas has its own unique methodologies, applications, and challenges. GenAI, with its ability to create content such as text, images, and even music, is indeed impressive. However, it is not the entirety of AI. Understanding the full spectrum of AI technologies is crucial for effectively leveraging their potential and addressing specific problems with the most appropriate tools.</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c3"><span class="c30">As I embarked on my own journey to demystify Generative AI (GenAI) and Large Language Models (LLMs), I found myself navigating through a sea of complex concepts and terminologies. I realized that the key to understanding these technologies was not just about learning the definitions, but about connecting the dots between them. This led me to adopt a question-and-answer approach, where each question opened up new avenues of knowledge and each answer built upon the last. In the following section, you&rsquo;ll find a series of these questions and answers that have shaped my understanding of GenAI and LLMs. They are presented from the perspective of an experienced software developer, focusing on practical, applicable knowledge. Whether you&rsquo;re just starting out with GenAI or looking to deepen your understanding, my hope is that this resource will serve as a guiding light on your own learning journey, just as these questions have been for me. Let&rsquo;s dive in!</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c2 subtitle" id="h.wj4a5gpe0w1"><span class="c13 c1">What is GenAI?</span></p><p class="c3"><span class="c1">Generative AI (GenAI) is a subset of AI that focuses on creating new content, rather than simply analyzing existing data.</span><span>&nbsp;One of the most prominent examples of GenAI is Large Language Models (LLMs). LLMs are trained on massive datasets of text and code, allowing them to generate human-quality text, translate languages, write different kinds of creative content, and answer your</span><span class="c24">&nbsp;1 </span><span>questions in an informative way.</span><span class="c24">&nbsp;2 </span><span class="c0">These models have the potential to revolutionize various industries, from content creation and customer service to research and education.</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c12"><span>While LLMs focus on text generation, GenAI can also create other forms of content. Here are a few examples:</span></p><ul class="c10 lst-kix_950oqqc6e3hw-0 start"><li class="c4 li-bullet-0"><span class="c1">Image Generation:</span><span class="c0">&nbsp;Models like DALL-E 2 and Midjourney can generate highly realistic images from text descriptions.</span></li><li class="c4 li-bullet-0"><span class="c1">Music Composition:</span><span class="c0">&nbsp;AI can create original musical pieces, mimicking different styles and genres. &nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Video Generation:</span><span class="c0">&nbsp;GenAI can be used to generate short videos, animations, or even entire movies. &nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Code Generation:</span><span class="c0">&nbsp;AI can write code based on natural language prompts or existing code snippets. &nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Drug Discovery:</span><span class="c0">&nbsp;GenAI can be used to design new molecules for potential drugs.</span></li></ul><p class="c3 c5"><span class="c0"></span></p><p class="c2 subtitle" id="h.wkwm84u7m08z"><span class="c13 c1">What is a Large Language Model?</span></p><p class="c3"><span class="c0">Large Language Models (LLMs) are a type of generative AI that excel at processing and generating human-quality text. They are typically built on neural network architectures, such as transformers, which are designed to handle sequential data like text. These models are trained on massive datasets of text, allowing them to learn complex patterns, relationships, and nuances of language. Some popular LLMs, like GPT-3 and LaMDA, differ in terms of their size, training data, and specific capabilities. For example, GPT-3 is known for its ability to generate creative text formats, while LaMDA is designed for conversational AI and understanding natural language queries.</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c2 subtitle" id="h.7enwvop7qeaq"><span class="c13 c1">What does the downloaded LLM file contain?</span></p><p class="c3"><span class="c0">When you download an LLM, you&#39;re typically getting a model file that contains the parameters and weights learned during the training process. These parameters and weights define the model&#39;s behavior and determine how it processes and generates text. Essentially, the LLM file is a representation of the model&#39;s knowledge and understanding of the world.</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c2 subtitle" id="h.f9orlw5ihquw"><span class="c1 c13">How do we interact with LLM?</span></p><p class="c3"><span class="c1">Interacting with an LLM typically involves using an API (Application Programming Interface).</span><span class="c0">&nbsp;This API acts as a bridge between the developer&#39;s application and the underlying LLM model.</span></p><p class="c3"><span class="c1">Typically, the LLM creator or provider offers the API.</span><span class="c0">&nbsp;This API is specifically designed to work with their particular LLM, ensuring compatibility and optimal performance. However, there are also some generic frameworks, like Hugging Face Transformers, that provide tools and libraries for working with various LLMs, including those from different providers.</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c2 subtitle" id="h.fcnivnej9e2b"><span class="c13 c1">What are the popular Tools and Frameworks for LLMs?</span></p><p class="c3"><span class="c0">This answer is subjective to personal choice and is time sensitive. The field is moving so fast that the list below may become outdated very soon. The frameworks and tools can be divided into categories based on their primary use cases:</span></p><h3 class="c6" id="h.4ce5tiuls0uk"><span class="c21 c1">1. Model Development and Training:</span></h3><ul class="c10 lst-kix_s6uqenm43v18-0 start"><li class="c4 li-bullet-0"><span class="c1">TensorFlow:</span><span class="c0">&nbsp;A flexible platform for building and training LLMs.</span></li><li class="c4 li-bullet-0"><span class="c1">PyTorch:</span><span class="c0">&nbsp;A dynamic computational graph framework for deep learning.</span></li><li class="c4 li-bullet-0"><span class="c1">Hugging Face Transformers:</span><span class="c0">&nbsp;Provides pre-trained LLMs and tools for fine-tuning.</span></li><li class="c4 li-bullet-0"><span class="c1">Ollama:</span><span class="c0">&nbsp;A modular, open-source framework for building and running LLMs, offering flexibility and customization.</span></li></ul><h3 class="c6" id="h.49zeghysvu55"><span class="c21 c1">2. Model Fine-tuning and Adaptation:</span></h3><ul class="c10 lst-kix_j78f6nqeir9j-0 start"><li class="c4 li-bullet-0"><span class="c1">Hugging Face Transformers:</span><span class="c0">&nbsp;Offers tools for adapting pre-trained models to specific tasks.</span></li><li class="c4 li-bullet-0"><span class="c1">EleutherAI&#39;s GPT-NeoX:</span><span class="c0">&nbsp;A suite of tools for training and fine-tuning large-scale models.</span></li><li class="c4 li-bullet-0"><span class="c1">DeepMind&#39;s AlphaFold:</span><span class="c0">&nbsp;Techniques for fine-tuning LLMs, originally developed for protein structure prediction.</span></li></ul><h3 class="c6" id="h.9ioo60fgtzg8"><span class="c1 c21">3. LLM Integration into Applications:</span></h3><ul class="c10 lst-kix_rv0f7hiv8gcy-0 start"><li class="c4 li-bullet-0"><span class="c1">Hugging Face Transformers:</span><span class="c0">&nbsp;Can be easily integrated into various software projects.</span></li><li class="c4 li-bullet-0"><span class="c1">LangChain:</span><span class="c0">&nbsp;A framework for simplifying LLM integration into applications.</span></li><li class="c4 li-bullet-0"><span class="c1">Cohere:</span><span class="c0">&nbsp;A cloud-based platform offering pre-trained LLMs and APIs.</span></li><li class="c4 li-bullet-0"><span class="c1">OpenAI API:</span><span class="c0">&nbsp;Provides access to OpenAI&#39;s powerful language models.</span></li></ul><h3 class="c6" id="h.rdjtp5g8gobv"><span class="c21 c1">4. LLM Deployment and Management:</span></h3><ul class="c10 lst-kix_kkmtp1dl1dg0-0 start"><li class="c4 li-bullet-0"><span class="c1">Hugging Face Hub:</span><span class="c0">&nbsp;A platform for sharing and deploying LLMs.</span></li><li class="c4 li-bullet-0"><span class="c1">Ollama:</span><span class="c0">&nbsp;A modular framework that can be used for deploying and managing LLMs, especially for custom models.</span></li><li class="c4 li-bullet-0"><span class="c1">AWS SageMaker:</span><span class="c0">&nbsp;A cloud-based platform for building, training, and deploying machine learning models, including LLMs.</span></li><li class="c4 li-bullet-0"><span class="c1">Google Cloud AI Platform:</span><span class="c0">&nbsp;Similar to AWS SageMaker, providing tools for LLM deployment and management.</span></li></ul><p class="c11 subtitle" id="h.ajrmqhay2037"><span class="c13 c1">What is Training, Pretraining, Fine-tuning, and Prompt Tuning?</span></p><h3 class="c6" id="h.wk061lp1jayo"><span class="c21 c1">Training</span></h3><ul class="c10 lst-kix_j5ci3q21dttk-0 start"><li class="c4 li-bullet-0"><span class="c1">Definition:</span><span class="c0">&nbsp;The process of teaching a neural network to perform a specific task by feeding it large amounts of data and adjusting its parameters.</span></li><li class="c4 li-bullet-0"><span class="c1">Who does it:</span><span class="c0">&nbsp;Typically large tech companies or research institutions with significant computational resources.</span></li><li class="c4 li-bullet-0"><span class="c1">Resources:</span><span class="c0">&nbsp;Massive datasets, powerful hardware (GPUs, TPUs), and specialized software frameworks.</span></li></ul><h3 class="c6" id="h.qyg79od2mr87"><span class="c21 c1">Pretraining</span></h3><ul class="c10 lst-kix_bkfzrqrpqj20-0 start"><li class="c4 li-bullet-0"><span class="c1">Definition:</span><span class="c0">&nbsp;A technique where a model is trained on a large, general-purpose dataset before being adapted to a specific task.</span></li><li class="c4 li-bullet-0"><span class="c1">Who does it:</span><span class="c0">&nbsp;Large tech companies or research institutions.</span></li><li class="c4 li-bullet-0"><span class="c1">Resources:</span><span class="c0">&nbsp;Enormous datasets, often publicly available corpora, and significant computational power.</span></li></ul><h3 class="c6" id="h.z1lkv8a7f6jp"><span class="c21 c1">Fine-tuning</span></h3><ul class="c10 lst-kix_d9oma2969bjs-0 start"><li class="c4 li-bullet-0"><span class="c1">Definition:</span><span class="c0">&nbsp;The process of adapting a pretrained model to a specific task by training it on a smaller, task-specific dataset.</span></li><li class="c4 li-bullet-0"><span class="c1">Who does it:</span><span class="c0">&nbsp;Domain experts, researchers, or organizations seeking to adapt LLMs to specific tasks.</span></li><li class="c4 li-bullet-0"><span class="c1">Resources:</span><span class="c0">&nbsp;Task-specific datasets, pre-trained models, and computational resources (though often less intensive than training or pretraining).</span></li></ul><h3 class="c6" id="h.bplt8cuivvhq"><span class="c21 c1">Prompt Tuning</span></h3><ul class="c10 lst-kix_tz6i84wciuj5-0 start"><li class="c4 li-bullet-0"><span class="c1">Definition:</span><span class="c0">&nbsp;A technique that involves modifying the input prompt to a language model to guide its response.</span></li><li class="c4 li-bullet-0"><span class="c1">Who does it:</span><span class="c0">&nbsp;Users or developers who want to interact with and control LLM outputs.</span></li><li class="c4 li-bullet-0"><span class="c1">Resources:</span><span class="c0">&nbsp;Access to a pre-trained LLM and knowledge of prompt engineering techniques.</span></li></ul><p class="c12 c5 c23"><span class="c0"></span></p><p class="c2 subtitle" id="h.axgjwsc6vu02"><span class="c13 c1">What is Prompt Engineering?</span></p><p class="c18 c3"><span class="c14">Prompt Engineering is a technique used in the field of Generative AI to effectively communicate with a Large Language Model (LLM). It involves crafting the input or &lsquo;prompt&rsquo; in a way that guides the model towards generating the desired output.</span></p><p class="c18 c3"><span class="c14">From a software developer&rsquo;s perspective, you can think of it as similar to writing a function call with specific parameters to get the desired return value. The better your parameters (or in this case, the prompt), the more likely you are to get the output you want.</span></p><p class="c18 c3"><span class="c14">Prompt Engineering can involve various strategies, such as:</span></p><ul class="c10 lst-kix_12qdo184rrs4-0 start"><li class="c22 li-bullet-0"><span class="c27 c1">Explicit Instruction:</span><span class="c14">&nbsp;Clearly stating the format or type of response you want from the model.</span></li><li class="c22 li-bullet-0"><span class="c27 c1">Contextual Framing:</span><span class="c14">&nbsp;Providing additional context or background information to guide the model&rsquo;s response.</span></li><li class="c22 li-bullet-0"><span class="c1 c27">Systematic Exploration:</span><span class="c14">&nbsp;Iteratively refining the prompt based on the model&rsquo;s previous outputs.</span></li></ul><p class="c18 c3"><span class="c14">The goal of Prompt Engineering is not just to get a correct response, but also to make the interaction with the model more efficient, reliable, and predictable. It&rsquo;s an essential skill for developers working with GenAI and LLMs, and it often requires a good understanding of the model&rsquo;s behavior and some creative problem-solving skills.</span></p><p class="c18 c3 c5"><span class="c14"></span></p><p class="c18 c3 c26 subtitle" id="h.3id0aj41ba1r"><span class="c13 c1">What is Retrieval-Augmented Generation (RAG)?</span></p><p class="c18 c3"><span class="c14">Retrieval-Augmented Generation (RAG) is a method used in Generative AI that combines the best of both retrieval-based and generative models.</span></p><p class="c18 c3"><span class="c14">In a typical generative model, the model generates responses based on a fixed knowledge that was learned during training. However, RAG models enhance this process by retrieving relevant documents or information from a large corpus at runtime, and then generating a response based on both the retrieved information and the original prompt.</span></p><p class="c18 c3"><span class="c14">From a software developer&rsquo;s perspective, you can think of RAG as a way to make your AI model more dynamic and adaptable. Instead of being limited to what it learned during training, a RAG model can pull in new information from a database or document collection, allowing it to provide more accurate and up-to-date responses.</span></p><p class="c18 c3"><span class="c14">RAG models are particularly useful in scenarios where the information landscape is constantly changing, such as news updates, customer support, or any other domain where real-time information is crucial.</span></p><p class="c18 c3"><span class="c14">Remember, while RAG models can be powerful, they also come with their own set of challenges, such as the need for a large and high-quality document collection, and increased computational requirements due to the retrieval step. As a developer, it&rsquo;s important to consider these factors when deciding whether to use a RAG model.</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c3"><span class="c0">If you want to learn more about RAG, learn about embedding too.</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c2 subtitle" id="h.6vorazr8enky"><span class="c13 c1">What are Embeddings?</span></p><p class="c18 c3"><span class="c14">Embeddings are a type of word representation that allows words with similar meaning to have a similar representation. They are a distributed representation for text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging natural language processing problems.</span></p><p class="c18 c3"><span class="c14">Embeddings are used to capture semantic and syntactic meanings of words in a high-dimensional space. This is achieved by representing words as dense vectors (as opposed to sparse vectors in techniques like Bag of Words). The position of a word within the vector space is learned from text and is based on the words that surround the word when it is used. Word embeddings can be trained using the input corpus itself or can be generated using pre-trained word embeddings such as Glove, FastText, and Word2Vec.</span></p><p class="c18 c3 c26 subtitle" id="h.fv1nuwo0nati"><span class="c13 c1">How are Embeddings used in RAG?</span></p><p class="c18 c3"><span class="c14">In the context of Retrieval-Augmented Generation (RAG), embeddings play a crucial role in the retrieval step. When a prompt is given to the RAG model, it converts the prompt into an embedding and then uses this embedding to retrieve relevant documents from a database or a large corpus of text.</span></p><p class="c3 c18"><span class="c14">The retrieved documents are also represented as embeddings. The model then compares the prompt embedding with the document embeddings to find the most relevant documents. These documents are then used to augment the generation process, allowing the model to generate responses that are not only based on its training data but also on the specific information contained in the retrieved documents.</span></p><p class="c18 c3"><span class="c14">This makes RAG models particularly useful in scenarios where real-time, up-to-date information is crucial. However, it&rsquo;s important to note that the quality of the embeddings can significantly impact the performance of a RAG model. As a developer, understanding how to generate and work with high-quality embeddings is a key skill when working with RAG models.</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c3 c5"><span class="c0"></span></p><p class="c2 subtitle" id="h.icjpmd32r8v2"><span class="c13 c1">What are different LLM Architectures?</span></p><p class="c12"><span>Large Language Models (LLMs) have primarily evolved around two main architectural frameworks: </span><span class="c1">Recurrent Neural Networks (RNNs)</span><span>&nbsp;and </span><span class="c1">Transformers</span><span class="c0">. These architectures have been instrumental in shaping the capabilities and advancements of LLMs.</span></p><p class="c3"><span class="c0">&nbsp;</span></p><h3 class="c6" id="h.58drm9ykfrt7"><span class="c21 c1">1. Recurrent Neural Networks (RNNs)</span></h3><p class="c12"><span class="c0">RNNs were among the early architectures used for LLMs. They are designed to process sequential data, making them suitable for natural language tasks. RNNs employ a hidden state that stores information about past inputs, allowing them to capture long-range dependencies in text. &nbsp;</span></p><ul class="c10 lst-kix_pe7i3notdr30-0 start"><li class="c4 li-bullet-0"><span class="c1">Long Short-Term Memory (LSTM):</span><span class="c0">&nbsp;A variant of RNNs, LSTMs are specifically designed to address the vanishing gradient problem, which can hinder the training of deep RNNs. LSTMs introduce &quot;gates&quot; (input, forget, and output) to regulate the flow of information, enabling them to learn long-term dependencies more effectively. &nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Gated Recurrent Units (GRUs):</span><span class="c0">&nbsp;A simpler variant of LSTMs, GRUs also address the vanishing gradient problem but use fewer gates, making them computationally efficient. &nbsp;</span></li></ul><h3 class="c6" id="h.ndq15gm25wuw"><span class="c21 c1">2. Transformers</span></h3><p class="c12"><span>Transformers have emerged as the dominant architecture for LLMs due to their ability to capture long-range dependencies and parallelize computations. They are based on the attention mechanism, which allows the model to weigh the importance of different parts of the input sequence when processing a specific part. &nbsp;</span></p><ul class="c10 lst-kix_o92df0wacpmc-0 start"><li class="c4 li-bullet-0"><span class="c1">Encoder-Decoder Architecture:</span><span class="c0">&nbsp;This is the most common architecture for LLMs, consisting of an encoder that processes the input sequence and a decoder that generates the output sequence. The attention mechanism is used to connect the encoder and decoder, allowing the decoder to attend to relevant parts of the input sequence. &nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Autoregressive Models:</span><span class="c0">&nbsp;These models are designed to generate text sequence by sequence. They use the attention mechanism to attend to previous tokens in the sequence, allowing them to generate coherent and contextually relevant text. &nbsp;</span></li></ul><h3 class="c6" id="h.63d2azfew798"><span class="c21 c1">Other Architectures</span></h3><p class="c12"><span class="c0">While RNNs and Transformers are the most prevalent, there are other architectures that have been explored for LLMs, including:</span></p><ul class="c10 lst-kix_ok66euexs0s0-0 start"><li class="c4 li-bullet-0"><span class="c1">Hybrid Models:</span><span class="c0">&nbsp;Combining elements of RNNs and Transformers to leverage their respective strengths. &nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Hierarchical Models:</span><span class="c0">&nbsp;Using hierarchical structures to capture different levels of information in text.</span></li><li class="c4 li-bullet-0"><span class="c1">Sparse Attention Models:</span><span class="c0">&nbsp;Reducing the computational complexity of attention by limiting the connections between different parts of the sequence. </span></li></ul><p class="c12"><span class="c0">The choice of architecture depends on factors such as the specific task, computational resources, and desired performance. Transformers have gained significant popularity due to their efficiency and ability to capture long-range dependencies, making them the preferred choice for many modern LLMs.</span></p><p class="c3 c5"><span class="c0"></span></p><p class="c2 subtitle" id="h.l4meipl00b8t"><span class="c13 c29">How do I learn more about GenAI?</span></p><p class="c3"><span>To have a good fundamental knowledge of GenAI and its application, I have provided </span><span class="c30">a structured roadmap to understanding GenAI and its applications. It outlines key topics and pairs them with valuable resources for deeper exploration. Please note that this guide serves as a navigational tool, pointing out the structure of the subject matter and providing resource pointers, but it does not delve into the content of each topic. Let&rsquo;s embark on this exciting journey of discovery in the world of GenAI!</span></p><ol class="c10 lst-kix_5sv5ylbljkvg-0 start" start="1"><li class="c12 c19 li-bullet-0"><span class="c17 c1">Generative AI</span></li></ol><ul class="c10 lst-kix_5sv5ylbljkvg-1 start"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Introduction to Generative Models</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Overview of generative models and their applications.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.ibm.com/topics/generative-ai&amp;sa=D&amp;source=editors&amp;ust=1727424703206812&amp;usg=AOvVaw2sSpmFnzzkIDmSetep3Aqu">IBM&rsquo;s Introduction to Generative AI</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.cloudskillsboost.google/course_templates/536&amp;sa=D&amp;source=editors&amp;ust=1727424703207174&amp;usg=AOvVaw3_yync6rYwUouyJGQn5t_a">Google Cloud Skills Boost</a></span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-1"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Variational Autoencoders (VAEs)</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Understanding VAEs and their use in generating new data.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: TensorFlow, Keras.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DHBYQvKlaE0A&amp;sa=D&amp;source=editors&amp;ust=1727424703207878&amp;usg=AOvVaw36bK9hpIReVlNKzQTF5cCH">DeepBean&rsquo;s VAE Tutorial</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://arxiv.org/abs/1606.05908&amp;sa=D&amp;source=editors&amp;ust=1727424703208223&amp;usg=AOvVaw3R6ri8Y1cPUtrf0yTkh7MY">Tutorial on Variational Autoencoders</a></span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-1"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Generative Adversarial Networks (GANs)</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Basics of GANs and their architecture.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: PyTorch, TensorFlow, Keras.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DMZmNxvLDdV0&amp;sa=D&amp;source=editors&amp;ust=1727424703209133&amp;usg=AOvVaw0gNtpUqkJrCpltnYCp50br">Simplilearn&rsquo;s GAN Tutorial</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.datacamp.com/tutorial/generative-adversarial-networks&amp;sa=D&amp;source=editors&amp;ust=1727424703209407&amp;usg=AOvVaw0RS5CJK7jiCKmpC8MP99KL">DataCamp&rsquo;s GAN Tutorial</a></span></li></ul><ol class="c10 lst-kix_5sv5ylbljkvg-0" start="2"><li class="c12 c19 li-bullet-0"><span class="c17 c1">Natural Language Processing (NLP)</span></li></ol><ul class="c10 lst-kix_5sv5ylbljkvg-1 start"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Text Preprocessing</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Techniques for cleaning and preparing text data.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: NLTK, SpaCy.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.freecodecamp.org/news/natural-language-processing-techniques-for-beginners/&amp;sa=D&amp;source=editors&amp;ust=1727424703210172&amp;usg=AOvVaw0_l0e7y2QbBIKaUvtGfYds">FreeCodeCamp&rsquo;s NLP Tutorial</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.analyticsvidhya.com/blog/2021/09/essential-text-pre-processing-techniques-for-nlp/&amp;sa=D&amp;source=editors&amp;ust=1727424703210423&amp;usg=AOvVaw24pNh5xPJF3BZU63PVMbvD">Analytics Vidhya&rsquo;s Text Preprocessing</a></span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-1"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Sentiment Analysis</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Methods for analyzing sentiment in text.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: TextBlob, VADER.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://research.aimultiple.com/sentiment-analysis-methods/&amp;sa=D&amp;source=editors&amp;ust=1727424703211085&amp;usg=AOvVaw0YAeo8l_Bf6llAzsMHS3fI">AIMultiple&rsquo;s Sentiment Analysis Methods</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://builtin.com/machine-learning/sentiment-analysis&amp;sa=D&amp;source=editors&amp;ust=1727424703211332&amp;usg=AOvVaw2tRXhGZD-2I_QuWSsguhbN">Built In&rsquo;s Sentiment Analysis Overview</a></span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-1"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Language Models (e.g., GPT, BERT)</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Understanding and using advanced language models.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: Transformers (Hugging Face), GPT-3 API.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DSZorAJ4I-sA&amp;sa=D&amp;source=editors&amp;ust=1727424703211988&amp;usg=AOvVaw1t09TGYkpGtHBEXUpQ2v4n">Google Cloud Tech&rsquo;s Transformers Explained</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://huggingface.co/blog/bert-101&amp;sa=D&amp;source=editors&amp;ust=1727424703212264&amp;usg=AOvVaw2kLAWGKH4ApwuPm6KgEHQL">Hugging Face&rsquo;s BERT 101</a></span></li></ul><ol class="c10 lst-kix_5sv5ylbljkvg-0" start="3"><li class="c12 c19 li-bullet-0"><span class="c17 c1">Data Visualization</span></li></ol><ul class="c10 lst-kix_5sv5ylbljkvg-1 start"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Matplotlib and Seaborn</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Creating static visualizations.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: Matplotlib, Seaborn.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.datacamp.com/tutorial/seaborn-python-tutorial&amp;sa=D&amp;source=editors&amp;ust=1727424703213012&amp;usg=AOvVaw0cCO7m7-LYrMm-A2ihoDov">DataCamp&rsquo;s Seaborn Tutorial</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.geeksforgeeks.org/python-seaborn-tutorial/&amp;sa=D&amp;source=editors&amp;ust=1727424703213276&amp;usg=AOvVaw3QBLAus0QN6Y6jEyU6oBsR">GeeksforGeeks&rsquo; Seaborn Tutorial</a></span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-1"><li class="c12 c16 li-bullet-0"><span class="c1 c17">Interactive Visualization with Plotly</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Building interactive plots and dashboards.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: Plotly, Dash.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DXhXNguOTnYA&amp;sa=D&amp;source=editors&amp;ust=1727424703213886&amp;usg=AOvVaw3cXvWstFKfhDq2zuKBLaDM">Epython Lab&rsquo;s Plotly Tutorial</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://programminghistorian.org/en/lessons/interactive-visualization-with-plotly&amp;sa=D&amp;source=editors&amp;ust=1727424703214160&amp;usg=AOvVaw2EEWteRpTNEDMQYYTdam1l">Programming Historian&rsquo;s Plotly Guide</a></span></li></ul><ol class="c10 lst-kix_5sv5ylbljkvg-0" start="4"><li class="c12 c19 li-bullet-0"><span class="c17 c1">Cloud Computing for Data Science</span></li></ol><ul class="c10 lst-kix_5sv5ylbljkvg-1 start"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Using AWS, Google Cloud, or Azure for Data Science</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Setting up cloud environments for data science projects.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: Boto3 (AWS), Google Cloud Client Libraries, Azure SDK.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D0SYV7o_fd50&amp;sa=D&amp;source=editors&amp;ust=1727424703214779&amp;usg=AOvVaw3WBQ0wLCimIPAMZYYRPtQp">AWS for Data Science Basics</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://cloud.google.com/blog/topics/developers-practitioners/intro-data-science-google-cloud&amp;sa=D&amp;source=editors&amp;ust=1727424703215041&amp;usg=AOvVaw17LQpIozlawiXe3if3rWBz">Google Cloud Blog&rsquo;s Intro to Data Science</a></span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-1"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Cloud-based Machine Learning Services</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Utilizing cloud services for machine learning.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: AWS SageMaker, Google AI Platform, Azure Machine Learning.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DChGx_wK7VaE&amp;sa=D&amp;source=editors&amp;ust=1727424703215673&amp;usg=AOvVaw01v63c1TlyweJB6ohcxq3g">DeepLearningAI&rsquo;s Practical Data Science on AWS</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.datacamp.com/tutorial/google-cloud-data-science&amp;sa=D&amp;source=editors&amp;ust=1727424703215933&amp;usg=AOvVaw2P551jDiSoX4oIwoL64Iti">DataCamp&rsquo;s Google Cloud Tutorial</a></span></li></ul><ol class="c10 lst-kix_5sv5ylbljkvg-0" start="5"><li class="c12 c19 li-bullet-0"><span class="c17 c1">Ethics in AI and Data Science</span></li></ol><ul class="c10 lst-kix_5sv5ylbljkvg-1 start"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Ethical Considerations in AI</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Understanding the ethical implications of AI.</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-1"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Bias and Fairness in AI Models</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Techniques to identify and mitigate bias.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: AIF360, Fairlearn.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span class="c0">: IBM&rsquo;s Ethics in AI, Fairlearn Documentation</span></li></ul><ol class="c10 lst-kix_5sv5ylbljkvg-0" start="6"><li class="c12 c19 li-bullet-0"><span class="c17 c1">Project Management and Collaboration</span></li></ol><ul class="c10 lst-kix_5sv5ylbljkvg-1 start"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Version Control with Git</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Using Git for version control and collaboration.</span></li><li class="c9 li-bullet-0"><span class="c1">Tools</span><span class="c0">: Git, GitHub, GitLab.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span class="c0">: GitHub&rsquo;s Git Tutorial, Atlassian&rsquo;s Git Tutorial</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-1"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Collaborative Tools</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Using tools for collaborative data science work.</span></li><li class="c9 li-bullet-0"><span class="c1">Python Packages</span><span class="c0">: Jupyter Notebooks, Google Colab.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span class="c0">: Jupyter Documentation, Google Colab Tutorial</span></li></ul><ol class="c10 lst-kix_5sv5ylbljkvg-0" start="7"><li class="c12 c19 li-bullet-0"><span class="c17 c1">Real-world Applications and Case Studies</span></li></ol><ul class="c10 lst-kix_5sv5ylbljkvg-1 start"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Case Studies of Data Science Projects</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Analyzing successful data science projects.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span class="c0">: Kaggle Case Studies, Data Science Central Case Studies</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-1"><li class="c12 c16 li-bullet-0"><span class="c17 c1">Applications of Generative AI in Various Industries</span></li></ul><ul class="c10 lst-kix_5sv5ylbljkvg-2 start"><li class="c9 li-bullet-0"><span class="c0">Exploring how generative AI is used in healthcare, finance, entertainment, etc.</span></li><li class="c9 li-bullet-0"><span class="c1">Resources</span><span>: </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://news.mit.edu/2023/explained-generative-ai-1109&amp;sa=D&amp;source=editors&amp;ust=1727424703218430&amp;usg=AOvVaw3-MEJPXNLEwoYip4Jun7lX">MIT News on Generative AI</a></span><span>, </span><span class="c15"><a class="c8" href="https://www.google.com/url?q=https://www.ibm.com/topics/generative-ai&amp;sa=D&amp;source=editors&amp;ust=1727424703218788&amp;usg=AOvVaw0U0bFI1YwA4P9OwMpdoil6">IBM&rsquo;s Generative AI Applications</a></span></li></ul></body></html>